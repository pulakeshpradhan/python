{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2253a0c1",
   "metadata": {},
   "source": [
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078260fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from utils import compute_mean_std, EarlyStopping, setup_logger\n",
    "import config as cfg\n",
    "from dataset import ClimateDataset\n",
    "from model import QuantileDownscaler\n",
    "from loss import QuantileLoss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f102f9",
   "metadata": {},
   "source": [
    "## Dataset and dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c0d69",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Collect and sort file paths\n",
    "lr_paths = sorted(glob(os.path.join(cfg.DATA_DIR, 'lr_images', '*.nc')))\n",
    "hr_paths = sorted(glob(os.path.join(cfg.DATA_DIR, 'hr_images', '*.nc')))\n",
    "assert len(lr_paths) == len(hr_paths), \"LR and HR directories must contain same number of files\"\n",
    "\n",
    "# Random shuffle of indices\n",
    "rng = np.random.default_rng(42)\n",
    "indices = np.arange(len(lr_paths))\n",
    "rng.shuffle(indices)\n",
    "\n",
    "# 80:20 split index\n",
    "split_idx = int(0.8 * len(indices))\n",
    "\n",
    "train_idx = indices[:split_idx]\n",
    "test_idx  = indices[split_idx:]\n",
    "\n",
    "# Gather file lists\n",
    "train_lr_paths = [lr_paths[i] for i in train_idx]\n",
    "train_hr_paths = [hr_paths[i] for i in train_idx]\n",
    "\n",
    "test_lr_paths = [lr_paths[i] for i in test_idx]\n",
    "test_hr_paths = [hr_paths[i] for i in test_idx]\n",
    "\n",
    "print(f\"Train: {len(train_lr_paths)}, Test: {len(test_lr_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute the normalization stats for all the channels\n",
    "mean, std = compute_mean_std(train_lr_paths, num_samples=int(len(train_lr_paths) * 0.5), num_workers=30)\n",
    "\n",
    "train_dataset = ClimateDataset(\n",
    "    lr_paths=train_lr_paths, \n",
    "    hr_paths=train_hr_paths, \n",
    "    mean=mean, std=std, size=128\n",
    ")\n",
    "test_dataset = ClimateDataset(\n",
    "    lr_paths=test_lr_paths, \n",
    "    hr_paths=test_hr_paths, \n",
    "    mean=mean, std=std, size=128\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=cfg.NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e30e6",
   "metadata": {},
   "source": [
    "## Model, Loss, Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617beb2e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = QuantileDownscaler(\n",
    "    in_channels=cfg.IMG_CHANNELS, \n",
    "    num_channels=64, \n",
    "    num_blocks=16, \n",
    "    quantiles=[0.05, 0.5, 0.95]\n",
    ")\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "criterion = QuantileLoss(quantiles=[0.05, 0.5, 0.95])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b87cff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=50,\n",
    "    device=\"cuda\",\n",
    "    checkpoint_path=\"best_model.pth\",\n",
    "    patience=10,\n",
    "    log_file=\"train.log\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Train model with early stopping, checkpointing, and logging.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch nn.Module\n",
    "        train_loader: DataLoader\n",
    "        val_loader: DataLoader\n",
    "        criterion: loss function\n",
    "        optimizer: optimizer\n",
    "        num_epochs: max epochs\n",
    "        device: \"cuda\" or \"cpu\"\n",
    "        checkpoint_path: file to save best model\n",
    "        patience: early stopping patience\n",
    "        log_file: log file path\n",
    "    \"\"\"\n",
    "\n",
    "    logger = setup_logger(log_file)\n",
    "    early_stopping = EarlyStopping(patience=patience, path=checkpoint_path)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # -------------------\n",
    "        # Training\n",
    "        # -------------------\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\"):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X)\n",
    "            print(preds.shape)\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * X.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # -------------------\n",
    "        # Validation\n",
    "        # -------------------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X, y in tqdm(val_loader, desc=f\"Epoch {epoch}/{num_epochs} [Val]\"):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                preds = model(X)\n",
    "                loss = criterion(preds, y)\n",
    "                val_loss += loss.item() * X.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        logger.info(\n",
    "            f\"Epoch [{epoch}/{num_epochs}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        # -------------------\n",
    "        # Checkpoint & Early Stopping\n",
    "        # -------------------\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            logger.info(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fa256",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=cfg.NUM_EPOCHS,\n",
    "        device=cfg.DEVICE,\n",
    "        checkpoint_path=os.path.join(cfg.CHECKPOINT_DIR, \"best_model.pth\"),\n",
    "        patience=10,\n",
    "        log_file=os.path.join(cfg.LOG_DIR, \"train.log\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d232c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X, y = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ea9f9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X_hat = model(X.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ec443",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(X.cpu().detach().numpy()[12])\n",
    "plt.colorbar(shrink=0.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d941c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f307ea",
   "metadata": {},
   "source": [
    "![png](train_files/train_11_0.png)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9c543",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(X_hat[0].mean(axis=0).cpu().detach().numpy())\n",
    "plt.colorbar(shrink=0.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80feda59",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "686d5b29",
   "metadata": {},
   "source": [
    "![png](train_files/train_12_0.png)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78144838",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(y.cpu().detach().numpy()[0])\n",
    "plt.colorbar(shrink=0.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700e747f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc1ee2b",
   "metadata": {},
   "source": [
    "![png](train_files/train_13_0.png)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Datasets and DataLoaders**\n",
    "In PyTorch, `Dataset` and `DataLoader` are fundamental for handling data. Here's a breakdown of how they work and how to use them:\n",
    "\n",
    "**1. Dataset**\n",
    "The Dataset class is essentially a blueprint. When you create a custom Dataset, you decide how data is loaded and returned. It defines:\n",
    "- `__init__()`: which tells how data should be loaded.\n",
    "- `__len__()`: which returns the total number of samples.\n",
    "- `__getitem__(index)`: which returns the data (and label) at the given index.\n",
    "\n",
    "**2. DataLoader**\n",
    "The DataLoader wraps a Dataset and handles batching, shuffling, and parallel loading for you.\n",
    "\n",
    "DataLoader Control Flow:\n",
    "- At the start of each epoch, the DataLoader (if shuffle=True) shuffles indices(using a sampler).\n",
    "- It divides the indices into chunks of batch_size.\n",
    "- for each index in the chunk, data samples are fetched from the Dataset object\n",
    "- The samples are then collected and combined into a batch (using collate_fn)\n",
    "- The batch is returned to the main training loop\n",
    "\n",
    "**Tips:**\n",
    "1. **Custom Collate Function**: For datasets that have variable-length inputs, you can use a custom collate function.\n",
    "2. **Lazy Loading**: If your dataset is too large, implement lazy loading in the `__getitem__` method by loading data directly from files.\n",
    "3. **Data Augmentation**: Use `torchvision.transforms` for on-the-fly data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **A Note about Samplers**\n",
    "In PyTorch, the sampler in the DataLoader determines the strategy for selecting samples from the dataset during data loading. It controls how indices of the dataset are drawn for each batch.\n",
    "\n",
    "**Types of Samplers:**\n",
    "PyTorch provides several predefined samplers, and you can create custom ones:\n",
    "1. `SequentialSampler`:\n",
    "   - Samples elements sequentially, in the order they appear in the dataset.\n",
    "   - Default when shuffle=False.\n",
    "2. `RandomSampler`:\n",
    "   - Samples elements randomly without"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **A Note about `collate_fn`**\n",
    "The collate_fn in PyTorch's DataLoader is a function that specifies how to combine a list of samples from a dataset into a single batch. By default, the DataLoader uses a simple batch collation mechanism, but collate_fn allows you to customize how the data should be processed and batched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Important Parameters of DataLoader**\n",
    "The DataLoader class in PyTorch comes with several parameters that allow you to customize how data is loaded, batched, and preprocessed. Some of the most commonly used and important parameters include:\n",
    "\n",
    "1. **dataset (mandatory)**:\n",
    "    - The Dataset from which the DataLoader will pull data.\n",
    "    - Must be a subclass of torch.utils.data.Dataset that implements `__getitem__` and `__len__`.\n",
    "\n",
    "2. **batch_size**:\n",
    "    - How many samples per batch to load.\n",
    "    - Default is 1.\n",
    "    - Larger batch sizes can speed up training on GPUs but require more memory.\n",
    "\n",
    "3. **shuffle**:\n",
    "    - If True, the DataLoader will shuffle the dataset indices each epoch.\n",
    "    - Helpful to avoid the model becoming too dependent on the order of samples.\n",
    "\n",
    "4. **num_workers**:\n",
    "    - The number of worker processes used to load data in parallel.\n",
    "    - Setting num_workers > 0 can speed up data loading by leveraging multiple CPU cores, especially if I/O or preprocessing is a bottleneck.\n",
    "\n",
    "5. **pin_memory**:\n",
    "    - If True, the DataLoader will copy tensors into pinned (page-locked) memory before returning them.\n",
    "    - This can improve GPU transfer speed and thus overall training throughput, particularly on CUDA systems.\n",
    "\n",
    "6. **drop_last**:\n",
    "    - If True, the DataLoader will drop the last incomplete batch if the total number of samples is not divisible by the batch size.\n",
    "    - Useful when exact batch sizes are required (for example, in some batch normalization scenarios).\n",
    "\n",
    "7. **collate_fn**:\n",
    "    - A callable that processes a list of samples into a batch (the default simply stacks tensors).\n",
    "    - Custom collate_fn can handle variable-length sequences, perform custom batching logic, or handle complex data structures.\n",
    "\n",
    "8. **sampler**:\n",
    "    - sampler defines the strategy for drawing samples (e.g., for handling imbalanced classes, or custom sampling strategies).\n",
    "    - batch_sampler works at the batch level, controlling how batches are formed.\n",
    "    - Typically, you don’t need to specify these if you are using batch_size and shuffle. However, they provide lower-level control if you have advanced requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the breast cancer dataset using Pandas\n",
    "data = pd.read_csv(r\"D:\\GITHUB\\pytorch-for-deep-Learning-and-machine-learning\\datasets\\breast_cancer_data.csv\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the irrelevant columns\n",
    "data.drop(columns=['id', 'Unnamed: 32'], inplace=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30), (398,), (171,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(columns=['diagnosis']),\n",
    "    data['diagnosis'],\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 398 entries, 149 to 102\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   radius_mean              398 non-null    float64\n",
      " 1   texture_mean             398 non-null    float64\n",
      " 2   perimeter_mean           398 non-null    float64\n",
      " 3   area_mean                398 non-null    float64\n",
      " 4   smoothness_mean          398 non-null    float64\n",
      " 5   compactness_mean         398 non-null    float64\n",
      " 6   concavity_mean           398 non-null    float64\n",
      " 7   concave points_mean      398 non-null    float64\n",
      " 8   symmetry_mean            398 non-null    float64\n",
      " 9   fractal_dimension_mean   398 non-null    float64\n",
      " 10  radius_se                398 non-null    float64\n",
      " 11  texture_se               398 non-null    float64\n",
      " 12  perimeter_se             398 non-null    float64\n",
      " 13  area_se                  398 non-null    float64\n",
      " 14  smoothness_se            398 non-null    float64\n",
      " 15  compactness_se           398 non-null    float64\n",
      " 16  concavity_se             398 non-null    float64\n",
      " 17  concave points_se        398 non-null    float64\n",
      " 18  symmetry_se              398 non-null    float64\n",
      " 19  fractal_dimension_se     398 non-null    float64\n",
      " 20  radius_worst             398 non-null    float64\n",
      " 21  texture_worst            398 non-null    float64\n",
      " 22  perimeter_worst          398 non-null    float64\n",
      " 23  area_worst               398 non-null    float64\n",
      " 24  smoothness_worst         398 non-null    float64\n",
      " 25  compactness_worst        398 non-null    float64\n",
      " 26  concavity_worst          398 non-null    float64\n",
      " 27  concave points_worst     398 non-null    float64\n",
      " 28  symmetry_worst           398 non-null    float64\n",
      " 29  fractal_dimension_worst  398 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 96.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Print the column information\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30) (171, 30)\n"
     ]
    }
   ],
   "source": [
    "# Scale the input variables using standarad scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled =scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398,) (171,)\n"
     ]
    }
   ],
   "source": [
    "# Encode the target variable using label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(y_train_encoded.shape, y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Convert NumPy Arrays to PyTorch Tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([398, 30]) torch.Size([171, 30]) (398,) (171,)\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train_scaled).type(torch.float32)\n",
    "X_test_tensor = torch.from_numpy(X_test_scaled).type(torch.float32)\n",
    "y_train_tensor = torch.from_numpy(y_train_encoded).type(torch.float32)\n",
    "y_test_tensor = torch.from_numpy(y_test_encoded).type(torch.float32)\n",
    "\n",
    "print(X_train_tensor.shape, X_test_tensor.shape, y_train_encoded.shape, y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create Dataset and DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custon dataset class\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the training dataset: 398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-0.7975, -0.3776, -0.8148, -0.7253, -0.5369, -0.9810, -0.7749, -0.7285,\n",
       "         -0.7530, -0.4882, -0.7349,  0.6774, -0.7181, -0.5517, -0.5347, -0.8574,\n",
       "         -0.6873, -0.9723, -0.8696, -0.8052, -0.6753,  1.7994, -0.6747, -0.6325,\n",
       "          0.5883, -0.5853, -0.4461, -0.4210,  0.1446, -0.3479]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an object of the custom dataset class\n",
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "print('Length of the training dataset:', train_dataset.__len__())\n",
    "# Print a row from train dataset\n",
    "train_dataset.__getitem__(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1452e+00, -1.0910e-01,  1.1560e+00,  1.0413e+00,  1.3702e+00,\n",
      "          8.8371e-01,  1.1465e+00,  1.5283e+00,  1.0766e+00,  6.0239e-02,\n",
      "          1.4786e+00,  7.5068e-01,  9.4802e-01,  1.1923e+00, -1.0144e+00,\n",
      "          2.3669e-01, -1.3624e-01, -4.3428e-01,  7.9533e-01,  5.0428e-01,\n",
      "          8.9966e-01, -2.2888e-01,  8.3943e-01,  7.7039e-01, -1.6404e-01,\n",
      "         -1.3060e-01, -3.1637e-02,  2.9247e-01,  2.2173e-01, -2.0962e-01],\n",
      "        [-5.7092e-01, -2.6829e-01, -5.7572e-01, -5.7049e-01, -3.7034e-01,\n",
      "         -4.8731e-01, -7.5781e-01, -8.8067e-01, -1.2635e+00,  2.4323e-02,\n",
      "         -6.3908e-01, -2.6271e-02, -5.6705e-01, -4.9849e-01, -6.8902e-01,\n",
      "         -4.8386e-01, -6.0930e-01, -1.0865e+00, -7.2847e-01, -7.3006e-01,\n",
      "         -6.1484e-01,  3.9342e-01, -5.6092e-01, -5.8671e-01, -4.7716e-01,\n",
      "         -1.4273e-01, -5.4365e-01, -8.9238e-01, -7.6639e-01, -3.5708e-01],\n",
      "        [ 1.3151e+00,  6.6785e-01,  1.2962e+00,  1.2562e+00,  4.2463e-01,\n",
      "          6.9601e-01,  9.1756e-01,  1.0355e+00,  5.2136e-01, -1.8565e-01,\n",
      "          1.4282e+00,  1.4023e+00,  7.6615e-01,  1.2966e+00,  3.2800e-01,\n",
      "          8.6376e-01,  6.9795e-01,  1.0302e+00,  4.3187e-01,  2.7350e-01,\n",
      "          1.3294e+00,  9.0257e-01,  1.1481e+00,  1.2651e+00,  3.1434e-01,\n",
      "          6.5493e-01,  6.2638e-01,  8.9274e-01,  1.9923e-01, -2.2715e-02],\n",
      "        [-7.7198e-01,  4.3025e-01, -7.6039e-01, -7.2059e-01,  1.0356e+00,\n",
      "         -1.8933e-01, -5.4234e-01, -6.9322e-01,  1.4501e-01,  1.0203e+00,\n",
      "         -2.7471e-01,  1.8708e+00, -3.7808e-01, -3.2726e-01,  1.0663e+00,\n",
      "         -4.6160e-01, -2.1319e-01, -7.0989e-01, -2.7632e-01,  6.9918e-02,\n",
      "         -6.6282e-01,  1.1072e+00, -6.9106e-01, -6.2583e-01,  1.0406e+00,\n",
      "         -5.4897e-01, -4.7474e-01, -8.2390e-01, -1.9441e-01,  2.8422e-01],\n",
      "        [-3.3588e-01, -1.1712e+00, -3.3704e-01, -4.0587e-01, -9.7592e-02,\n",
      "         -7.1429e-02, -6.5207e-01, -7.2907e-01, -5.6296e-01,  1.3422e+00,\n",
      "         -7.7007e-01, -1.0843e+00, -9.2515e-01, -5.3638e-01, -5.8612e-01,\n",
      "         -1.2831e-01, -3.7627e-02, -7.4057e-01, -4.9740e-01,  7.2146e-01,\n",
      "         -5.3557e-01, -1.4302e+00, -6.0481e-01, -5.3654e-01, -7.6419e-01,\n",
      "         -3.4753e-01, -6.3043e-01, -8.6731e-01, -7.2461e-01,  9.9238e-01],\n",
      "        [-4.1800e-01, -1.6606e+00, -4.6895e-01, -4.5972e-01, -5.8999e-01,\n",
      "         -8.8697e-01, -8.2933e-01, -6.4835e-01, -8.2007e-01,  1.1891e-02,\n",
      "         -6.1874e-01, -1.0756e+00, -6.3857e-01, -4.7575e-01, -2.9674e-01,\n",
      "         -7.0809e-01, -7.7237e-01, -5.9345e-01, -4.0497e-01,  2.3535e-01,\n",
      "         -5.5017e-01, -1.4285e+00, -5.8241e-01, -5.5251e-01, -1.6180e-02,\n",
      "         -5.9545e-01, -8.9155e-01, -4.9524e-01, -1.7352e-01,  6.3458e-01],\n",
      "        [-1.2766e+00, -2.5166e-01, -1.2860e+00, -1.0420e+00, -9.3475e-01,\n",
      "         -9.5853e-01, -9.4266e-01, -1.1329e+00, -4.5863e-01,  2.0114e-01,\n",
      "         -2.1783e-01,  2.0893e-01, -2.8431e-01, -4.0181e-01,  1.2624e+00,\n",
      "         -7.1143e-01, -7.3123e-01, -1.2836e+00,  8.1906e-01, -3.0665e-01,\n",
      "         -1.0717e+00, -1.4735e-01, -1.0972e+00, -8.8003e-01,  3.0564e-01,\n",
      "         -8.3259e-01, -1.0435e+00, -1.3923e+00,  2.7957e-01, -2.7363e-01],\n",
      "        [ 3.6358e-01, -1.7271e+00,  4.2226e-01,  2.1520e-01,  2.1630e+00,\n",
      "          1.0206e+00,  1.4810e+00,  1.6265e+00,  6.0706e-01,  1.1087e+00,\n",
      "          5.5539e-02, -1.0513e+00, -3.3296e-02,  8.2804e-02, -5.3404e-01,\n",
      "         -1.1941e-01,  3.5881e-01,  2.0464e-01, -3.0630e-01,  1.4244e-01,\n",
      "          5.2208e-01, -1.4086e+00,  5.3376e-01,  3.8621e-01,  9.2754e-01,\n",
      "          7.3577e-01,  1.6055e+00,  1.0792e+00,  5.3503e-01,  9.9810e-01],\n",
      "        [-8.2012e-01, -1.3707e+00, -7.9378e-01, -7.6719e-01,  1.4865e+00,\n",
      "          2.0133e-01, -5.3668e-01, -1.2736e-02, -1.1955e-01, -2.6853e-01,\n",
      "         -2.2886e-01,  2.6870e-01, -4.8512e-01, -2.9223e-01,  1.3556e+00,\n",
      "          5.3548e-01, -3.4612e-01,  1.2406e+00, -5.7109e-01, -1.3177e-01,\n",
      "         -9.1106e-01, -1.6199e+00, -9.3318e-01, -7.8565e-01,  2.1431e-01,\n",
      "         -4.5061e-01, -9.2810e-01, -4.3459e-01, -1.2548e+00, -8.9721e-01],\n",
      "        [-5.5676e-01, -2.7067e-01, -5.7489e-01, -5.6184e-01, -2.6561e-01,\n",
      "         -6.1694e-01, -5.6794e-01, -7.4792e-01, -4.0274e-01, -4.8402e-01,\n",
      "         -5.2429e-01, -8.1942e-01, -4.7422e-01, -4.5117e-01, -3.9256e-01,\n",
      "         -6.3854e-01, -4.0841e-01, -7.7719e-01, -1.2394e-01, -6.9153e-01,\n",
      "         -4.1666e-01, -2.4385e-01, -4.0899e-01, -4.5128e-01,  2.1866e-01,\n",
      "         -2.1616e-01, -1.3884e-01, -4.0042e-01,  5.3825e-01, -5.0511e-01],\n",
      "        [-3.6703e-01,  2.3192e+00, -4.0217e-01, -4.0587e-01, -1.0715e+00,\n",
      "         -8.8110e-01, -3.3601e-01, -6.6402e-01, -8.8341e-01, -7.7135e-01,\n",
      "         -6.6597e-01,  3.0147e-01, -6.5041e-01, -4.8681e-01,  4.3668e-01,\n",
      "         -2.1289e-01,  2.2389e-01, -6.9158e-01, -4.2745e-01, -3.7388e-01,\n",
      "         -5.0010e-01,  1.7029e+00, -5.6062e-01, -5.0198e-01, -3.9454e-01,\n",
      "         -5.8669e-01, -1.2557e-01, -7.6653e-01, -8.2101e-01, -6.3543e-01],\n",
      "        [ 4.7403e-01,  1.1383e+00,  4.7173e-01,  3.4298e-01, -8.6929e-01,\n",
      "         -6.0675e-02,  1.4548e-01,  1.3807e-01,  1.6364e-01, -1.2825e+00,\n",
      "         -5.1319e-03, -2.4220e-01,  1.3118e-02, -8.2285e-02,  8.7301e-01,\n",
      "          3.2850e-01,  6.0800e-01,  1.2840e+00,  1.1788e+00, -2.9796e-01,\n",
      "          1.1529e-01,  3.5848e-01,  1.4031e-01, -9.3823e-03, -8.1203e-01,\n",
      "         -3.8189e-01, -1.8529e-01, -3.0387e-02, -1.1889e-01, -1.1813e+00],\n",
      "        [-4.6331e-01, -2.5879e-01, -5.2914e-01, -4.6837e-01, -1.5712e+00,\n",
      "         -1.5017e+00, -1.1176e+00, -1.1414e+00, -1.0250e+00, -1.4938e+00,\n",
      "         -1.8508e-01, -4.8377e-01, -2.5873e-01, -2.5188e-01, -4.0864e-01,\n",
      "         -1.1497e+00, -1.0483e+00, -1.3345e+00,  7.2025e-03, -1.0322e+00,\n",
      "         -5.3557e-01, -7.5300e-01, -6.2176e-01, -5.1953e-01, -1.6892e+00,\n",
      "         -1.3866e+00, -1.3524e+00, -1.5279e+00, -1.0443e+00, -1.6191e+00],\n",
      "        [-4.9446e-01, -5.1302e-01, -5.6294e-01, -5.0911e-01, -1.4832e+00,\n",
      "         -1.3445e+00, -9.6028e-01, -8.3500e-01, -1.2337e+00, -9.7441e-01,\n",
      "         -9.3036e-02,  1.9209e+00, -1.8390e-01, -1.9330e-01,  9.7463e-02,\n",
      "         -8.1047e-01, -7.4292e-01, -1.1658e-01,  1.7433e+00, -3.1345e-01,\n",
      "         -7.0663e-01, -8.8112e-01, -7.7490e-01, -6.4197e-01, -2.0737e+00,\n",
      "         -1.3606e+00, -1.2564e+00, -1.3403e+00, -1.5778e+00, -1.3842e+00],\n",
      "        [ 1.0022e-01,  4.2965e-02,  8.2183e-02, -1.9769e-04, -8.7875e-01,\n",
      "         -4.9474e-01,  1.2764e-03, -5.0950e-01, -1.2299e+00, -7.1886e-01,\n",
      "         -5.2153e-01,  2.8991e-01, -4.1739e-01, -3.5962e-01, -9.3467e-01,\n",
      "         -2.7131e-01,  5.0989e-02, -4.9435e-01, -8.0341e-01, -5.5291e-01,\n",
      "          2.6448e-03,  4.7994e-01,  2.2280e-02, -9.0079e-02, -9.9469e-01,\n",
      "          1.0654e-01,  5.5848e-01, -2.8052e-01, -6.6195e-01, -5.0912e-01],\n",
      "        [-1.2177e+00,  5.7221e-02, -1.1668e+00, -1.0085e+00,  3.3008e-01,\n",
      "         -1.2383e-01, -3.4128e-01, -4.8188e-01,  5.2881e-01,  7.6816e-02,\n",
      "         -7.7387e-01,  3.5422e-02, -6.3809e-01, -5.9046e-01,  6.4440e-01,\n",
      "         -1.8896e-01, -6.5611e-02, -1.2943e-01, -5.3487e-01, -8.3429e-02,\n",
      "         -1.1530e+00,  2.2037e-01, -1.0636e+00, -9.1336e-01,  1.0493e+00,\n",
      "         -1.2723e-01, -2.0916e-02, -2.5623e-01, -4.1934e-01,  7.7881e-02],\n",
      "        [ 2.8713e-01, -1.4135e+00,  2.2234e-01,  1.4516e-01, -1.1879e+00,\n",
      "         -6.6407e-01, -6.9645e-01, -5.8065e-01, -3.0586e-01, -9.9790e-01,\n",
      "         -7.8076e-01, -1.5252e+00, -7.2808e-01, -4.6858e-01, -6.5654e-01,\n",
      "         -5.8457e-01, -5.5799e-01, -4.4504e-01, -4.8741e-01, -7.6443e-01,\n",
      "         -1.8216e-02, -1.6265e+00, -8.6674e-02, -1.1008e-01, -8.3378e-01,\n",
      "         -5.0787e-01, -6.7536e-01, -5.0245e-01, -6.3625e-01, -9.0750e-01],\n",
      "        [ 1.1055e+00,  6.3696e-01,  1.0365e+00,  1.0162e+00, -1.6184e+00,\n",
      "         -3.3011e-01,  2.8595e-01,  2.4799e-01, -1.2327e-01, -1.2797e+00,\n",
      "          7.9773e-01,  1.9544e-01,  6.8043e-01,  7.3251e-01, -4.8998e-01,\n",
      "          1.5359e+00,  9.6080e-01,  4.0380e-01,  1.2836e-01,  4.7028e-01,\n",
      "          7.2443e-01, -1.3404e-01,  6.5784e-01,  6.0724e-01, -1.8940e+00,\n",
      "         -3.5562e-01, -7.6559e-02, -3.4525e-01, -8.2583e-01, -1.0264e+00],\n",
      "        [-6.5304e-01,  5.6568e-01, -6.3590e-01, -6.3550e-01, -2.1698e+00,\n",
      "          6.0550e-02, -3.8691e-03, -6.5260e-01, -1.6920e+00,  4.7741e-01,\n",
      "         -5.1291e-01,  6.7549e-01, -4.3586e-01, -4.1697e-01, -6.4270e-02,\n",
      "          1.9627e+00,  1.1450e+00,  5.7887e-01,  3.9565e-01,  1.9392e+00,\n",
      "         -7.2957e-01,  4.4500e-01, -7.2193e-01, -6.5724e-01, -1.6179e+00,\n",
      "          6.1181e-01,  2.7210e-01, -4.1280e-01, -9.2866e-01,  9.1351e-01],\n",
      "        [ 1.8305e+00, -4.2986e-01,  1.7537e+00,  1.8839e+00, -1.0923e-01,\n",
      "          8.4014e-02,  8.3137e-01,  1.0878e+00, -8.6478e-01, -1.0891e+00,\n",
      "          7.2017e-01, -1.0529e+00,  5.8903e-01,  7.4603e-01, -2.7102e-01,\n",
      "         -3.5644e-01, -1.8154e-01,  6.3303e-02, -9.5079e-01, -7.8558e-01,\n",
      "          1.8947e+00, -3.8861e-01,  1.7988e+00,  1.8668e+00,  1.0624e+00,\n",
      "          3.8006e-01,  7.5247e-01,  1.5259e+00, -3.1169e-01, -7.4231e-01],\n",
      "        [-1.5589e+00, -1.1189e+00, -1.5597e+00, -1.2069e+00, -3.3325e-01,\n",
      "         -1.1838e+00, -1.1329e+00, -1.2861e+00, -3.0213e-01,  6.3213e-01,\n",
      "         -6.3563e-01, -8.0264e-01, -6.8214e-01, -5.9885e-01,  6.8105e-01,\n",
      "         -9.6532e-01, -1.0747e+00, -1.9155e+00,  8.4154e-01, -1.4802e-01,\n",
      "         -1.4655e+00, -1.4086e+00, -1.4831e+00, -1.0923e+00, -6.7722e-01,\n",
      "         -1.2027e+00, -1.3706e+00, -1.7842e+00, -4.6754e-01, -2.8906e-01],\n",
      "        [ 2.3332e-01, -8.6704e-01,  2.1409e-01,  6.8996e-02, -8.9111e-01,\n",
      "          1.2312e-01, -2.9613e-01, -2.8249e-01,  2.9033e-01, -4.9646e-01,\n",
      "         -5.9633e-01, -1.3631e+00, -2.8383e-01, -4.2434e-01, -9.4367e-01,\n",
      "          3.7357e-01,  1.3927e-01, -6.0370e-02, -8.0715e-01, -2.2167e-01,\n",
      "          2.5592e-02, -1.0309e+00,  2.0690e-01, -1.2920e-01, -7.9029e-01,\n",
      "          7.6541e-01,  3.6603e-01,  3.7710e-01,  1.1408e-01,  4.7204e-03],\n",
      "        [-5.5526e-02,  1.0949e-01, -4.6842e-02, -1.6816e-01,  7.3011e-01,\n",
      "          1.9546e-01,  3.1554e-01,  4.2986e-01, -4.9962e-01,  3.8348e-01,\n",
      "         -6.3425e-01, -4.8261e-01, -6.0305e-01, -4.4544e-01, -5.5944e-01,\n",
      "         -4.1431e-01, -3.4678e-01, -3.7887e-01, -1.0170e+00, -3.5689e-01,\n",
      "          1.5702e-01,  8.8094e-01,  1.9782e-01, -2.2013e-02,  1.2841e+00,\n",
      "          7.2566e-01,  7.0652e-01,  1.0792e+00,  4.7558e-01,  1.2553e+00],\n",
      "        [ 1.2438e-02,  9.4109e-01,  8.7129e-02, -1.3914e-01,  8.3921e-01,\n",
      "          2.6982e+00,  1.4154e+00,  4.7101e-01,  2.1646e+00,  1.7621e+00,\n",
      "         -4.0949e-01,  1.7474e+00, -3.6151e-01, -1.8183e-01,  2.9456e-01,\n",
      "          6.1229e+00,  2.8097e+00,  7.6037e-01,  3.8417e+00,  2.9948e+00,\n",
      "         -1.1418e-01,  1.9425e+00, -2.9171e-02, -2.0954e-01,  9.3623e-01,\n",
      "          4.6055e+00,  2.9624e+00,  9.9304e-01,  3.6681e+00,  3.4901e+00],\n",
      "        [-1.4898e-01, -1.4254e+00, -1.8040e-01, -2.5354e-01,  3.6237e-02,\n",
      "         -3.1662e-01, -6.3277e-01, -6.0561e-01, -1.6510e+00,  1.0721e-01,\n",
      "         -6.7079e-01, -1.4845e+00, -7.0298e-01, -4.7514e-01, -9.3917e-01,\n",
      "         -4.6772e-01, -5.2435e-01, -8.4593e-01, -8.3213e-01, -3.9881e-01,\n",
      "         -1.9762e-01, -1.5234e+00, -2.3164e-01, -3.0814e-01, -2.9226e-02,\n",
      "         -1.1359e-02, -4.7269e-01, -5.2157e-01, -8.0816e-01,  2.0820e-01],\n",
      "        [-1.4614e-01, -6.9310e-03, -1.1527e-01, -2.3568e-01, -3.9216e-01,\n",
      "          2.2284e-01,  1.0933e-01, -8.4880e-03,  1.6737e-01, -1.1796e-01,\n",
      "         -6.2184e-01, -5.9501e-01, -5.0738e-01, -4.3499e-01, -9.8837e-01,\n",
      "          1.5212e-01,  1.4760e-01,  1.3076e-01, -5.6984e-01,  6.2364e-02,\n",
      "         -2.3934e-01, -9.2392e-04, -1.8049e-01, -3.0357e-01, -7.4245e-01,\n",
      "          4.5551e-01,  4.9774e-01,  4.2099e-01, -2.2333e-01,  2.7736e-01],\n",
      "        [ 1.0404e+00, -1.4088e+00,  9.2105e-01,  9.2722e-01, -1.2788e+00,\n",
      "         -8.0426e-01, -5.6112e-01, -1.7682e-01, -2.1727e+00, -1.4137e+00,\n",
      "          2.7099e-01, -3.0389e-01,  1.3626e-01,  2.1205e-01, -8.6329e-01,\n",
      "         -9.5046e-01, -6.9058e-01, -7.2097e-01, -9.1832e-01, -9.3741e-01,\n",
      "          7.3695e-01, -1.1790e+00,  5.9731e-01,  5.7567e-01, -1.4418e+00,\n",
      "         -1.0060e+00, -8.3565e-01, -4.7690e-01, -1.7674e+00, -1.4190e+00],\n",
      "        [-5.6526e-01, -1.2068e+00, -6.1859e-01, -5.5347e-01, -1.3544e+00,\n",
      "         -1.3918e+00, -9.8846e-01, -1.1520e+00, -4.8471e-01, -8.5285e-01,\n",
      "         -6.6700e-01, -1.1645e+00, -6.8072e-01, -5.0750e-01, -5.5011e-01,\n",
      "         -1.0900e+00, -7.0058e-01, -1.1042e+00, -7.5232e-02, -1.0729e+00,\n",
      "         -7.1706e-01, -1.5034e+00, -7.7974e-01, -6.4689e-01, -1.3774e+00,\n",
      "         -1.3189e+00, -1.1605e+00, -1.4939e+00, -9.4794e-01, -1.3242e+00],\n",
      "        [-8.9508e-02, -5.2965e-01, -5.3437e-02, -2.2564e-01,  4.8282e-01,\n",
      "          9.4628e-01,  1.4072e-01,  2.0126e-01,  1.1287e+00,  8.9735e-01,\n",
      "         -5.1188e-01, -1.8560e-02, -4.4628e-01, -3.6679e-01, -3.5172e-01,\n",
      "          5.0210e-01,  2.2755e-01,  3.8935e-01, -1.2269e-01,  2.9050e-01,\n",
      "         -1.1209e-01,  2.3701e-01, -8.9700e-02, -2.3112e-01,  6.1876e-01,\n",
      "          1.2660e+00,  9.9597e-01,  8.0810e-01,  1.2002e+00,  1.2782e+00],\n",
      "        [-6.9835e-01, -8.8129e-01, -7.1010e-01, -6.6814e-01,  1.3847e+00,\n",
      "         -5.9622e-01, -6.1760e-01, -4.2321e-01,  7.6728e-01,  3.3099e-01,\n",
      "         -2.0748e-01, -8.9480e-01, -2.4642e-01, -3.2910e-01,  7.9809e-01,\n",
      "         -8.0045e-01, -5.2468e-01, -1.1498e-01, -1.0521e-01, -2.6095e-01,\n",
      "         -6.7325e-01, -1.2222e+00, -7.0226e-01, -6.4110e-01,  6.1876e-01,\n",
      "         -9.2691e-01, -8.1574e-01, -5.5166e-01, -1.8959e-01, -3.1307e-01],\n",
      "        [-7.9747e-01, -3.7758e-01, -8.1480e-01, -7.2534e-01, -5.3690e-01,\n",
      "         -9.8101e-01, -7.7492e-01, -7.2854e-01, -7.5300e-01, -4.8817e-01,\n",
      "         -7.3491e-01,  6.7742e-01, -7.1813e-01, -5.5174e-01, -5.3468e-01,\n",
      "         -8.5737e-01, -6.8725e-01, -9.7233e-01, -8.6961e-01, -8.0522e-01,\n",
      "         -6.7533e-01,  1.7994e+00, -6.7472e-01, -6.3250e-01,  5.8832e-01,\n",
      "         -5.8535e-01, -4.4615e-01, -4.2095e-01,  1.4461e-01, -3.4793e-01],\n",
      "        [-7.6915e-01, -2.3740e-01, -7.6946e-01, -7.1613e-01, -5.4054e-01,\n",
      "         -5.1547e-01, -7.0275e-01, -8.8731e-01, -1.4610e+00, -3.2313e-02,\n",
      "         -2.6540e-01, -2.7883e-01, -1.8959e-01, -3.6187e-01, -1.2922e-01,\n",
      "          6.4760e-02, -3.3479e-01, -6.6155e-01, -1.7890e-01, -1.4348e-01,\n",
      "         -7.5252e-01, -6.4818e-01, -7.4675e-01, -6.8776e-01, -7.5550e-01,\n",
      "         -4.7284e-01, -7.4478e-01, -9.2075e-01, -1.0845e+00, -4.0909e-01]])\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "--------------------------------------------------\n",
      "tensor([[-1.5873e+00, -1.4397e+00, -1.5551e+00, -1.2234e+00,  5.5555e-01,\n",
      "         -5.2759e-01, -8.0296e-01, -8.8518e-01, -4.6608e-01,  1.1874e+00,\n",
      "         -9.5864e-01, -1.0109e+00, -8.5548e-01, -6.8295e-01,  2.7109e-01,\n",
      "         -4.3044e-01, -4.7471e-01, -7.3976e-01, -5.5610e-01,  5.0656e-02,\n",
      "         -1.4215e+00, -1.1740e+00, -1.3336e+00, -1.0635e+00,  1.4059e+00,\n",
      "         -1.7237e-01, -4.7525e-01, -4.5010e-01,  1.6067e-01,  1.2210e+00],\n",
      "        [-1.3199e-01, -1.1385e-01, -1.4536e-01, -2.4768e-01,  2.3262e-01,\n",
      "          7.2282e-02, -4.4021e-01, -2.8169e-01, -3.3194e-01,  7.9651e-01,\n",
      "         -2.9539e-01,  8.7476e-02, -2.8005e-01, -2.8977e-01, -1.0125e-01,\n",
      "         -1.5836e-01, -3.7976e-01,  2.5604e-01, -2.0888e-01, -1.6576e-02,\n",
      "         -2.4560e-01,  2.0707e-02, -2.4012e-01, -3.1568e-01,  4.6655e-01,\n",
      "          5.0621e-02, -3.8285e-01,  2.2821e-01, -5.4623e-02,  3.8710e-01],\n",
      "        [-1.2588e+00, -9.0743e-01, -1.1738e+00, -1.0032e+00,  8.1739e-01,\n",
      "          1.1066e+00,  4.1515e+00,  7.9997e-01,  2.7757e+00,  4.1850e+00,\n",
      "          1.4468e+00,  2.8155e+00,  5.6724e-01,  1.8952e-01,  1.2592e+00,\n",
      "          3.9229e+00,  1.2118e+01,  6.5633e+00,  1.8845e+00,  9.8388e+00,\n",
      "         -1.0988e+00, -1.0009e+00, -1.0993e+00, -8.7950e-01, -1.1186e-01,\n",
      "          1.8940e-01,  2.8235e+00,  6.7802e-01,  3.6151e-01,  2.4213e+00],\n",
      "        [ 1.7668e-01, -3.5620e-01,  1.4937e-01,  4.1932e-02, -3.0343e-01,\n",
      "         -2.8162e-01, -6.0949e-01, -6.8606e-01,  3.3505e-01, -5.2546e-01,\n",
      "         -6.3563e-01, -1.1211e+00, -6.5988e-01, -4.2701e-01, -7.2599e-01,\n",
      "         -7.5928e-01, -4.8903e-01, -8.0770e-01,  2.7074e-01, -6.8738e-01,\n",
      "          2.9764e-02, -4.6016e-01, -4.4303e-02, -9.1833e-02, -3.9888e-01,\n",
      "         -4.1086e-01, -3.1904e-01, -4.8207e-01,  1.1520e+00, -6.1085e-01],\n",
      "        [-8.6676e-02, -7.0072e-01, -1.5402e-01, -1.8434e-01, -6.2054e-01,\n",
      "         -9.4601e-01, -9.3970e-01, -7.3172e-01, -1.4125e+00, -5.2961e-01,\n",
      "         -5.1877e-01,  3.0726e-01, -5.3911e-01, -4.0673e-01, -4.5526e-01,\n",
      "         -9.6910e-01, -8.9966e-01, -9.4503e-01, -6.1606e-01, -6.4356e-01,\n",
      "         -2.4560e-01,  1.2387e-02, -3.2153e-01, -3.2884e-01, -7.1636e-01,\n",
      "         -9.9900e-01, -1.1008e+00, -9.1339e-01, -8.3708e-01, -7.0916e-01],\n",
      "        [-9.9569e-01, -9.5257e-01, -1.0209e+00, -8.6540e-01, -5.8490e-01,\n",
      "         -1.1787e+00, -1.1329e+00, -1.2861e+00,  4.6546e-01, -4.0252e-01,\n",
      "         -2.5471e-01,  1.3907e+00, -3.4114e-01, -3.8133e-01,  5.3347e-01,\n",
      "         -8.4497e-01, -1.0747e+00, -1.9155e+00,  1.5335e+00, -1.0534e+00,\n",
      "         -9.9033e-01, -1.0492e+00, -1.0340e+00, -8.3073e-01, -1.0512e+00,\n",
      "         -1.2206e+00, -1.3706e+00, -1.7842e+00, -2.7795e-01, -1.2516e+00],\n",
      "        [ 8.0252e-01,  2.6156e-01,  7.1906e-01,  6.8225e-01, -5.9945e-01,\n",
      "         -5.9172e-01, -2.3889e-01,  1.4497e-01,  8.3063e-01, -1.4413e+00,\n",
      "          6.2399e-01, -6.7135e-01,  5.8287e-01,  5.7070e-01, -6.4818e-01,\n",
      "         -5.7455e-01, -4.2640e-01, -1.1177e-01,  3.2070e-01, -4.5698e-01,\n",
      "          7.3278e-01, -7.5799e-02,  6.8508e-01,  5.7567e-01, -8.9901e-01,\n",
      "         -6.7697e-01, -3.8438e-01, -6.6434e-02,  6.2983e-01, -1.0773e+00],\n",
      "        [-9.5605e-01, -2.2451e+00, -9.6815e-01, -8.4308e-01, -1.5844e-03,\n",
      "         -8.9831e-01, -8.0733e-01, -8.3527e-01, -1.5728e+00,  1.8456e-01,\n",
      "         -7.9972e-01, -1.5370e+00, -8.2848e-01, -5.9640e-01,  2.4280e-01,\n",
      "         -8.6466e-01, -7.0857e-01, -1.0571e+00, -9.7827e-01, -6.3110e-01,\n",
      "         -9.7782e-01, -2.2439e+00, -1.0200e+00, -8.2073e-01,  5.1439e-01,\n",
      "         -8.3125e-01, -8.3616e-01, -1.0627e+00, -1.2741e+00, -3.7423e-01],\n",
      "        [ 2.3049e-01,  7.0111e-01,  2.1739e-01,  9.4665e-02, -7.8637e-01,\n",
      "         -1.5704e-02, -2.5059e-01, -2.5700e-01,  5.2508e-01, -4.8817e-01,\n",
      "         -2.9711e-01,  2.5520e-01, -2.6773e-01, -2.4758e-01, -8.3757e-01,\n",
      "          1.5156e-01,  2.8668e-02,  5.4818e-03, -1.6391e-01,  8.4649e-02,\n",
      "          9.8605e-02,  1.0057e+00,  8.5836e-02, -2.5872e-02, -1.0469e+00,\n",
      "          5.7543e-01,  2.1901e-01,  2.6583e-01,  4.4988e-01,  5.1284e-01],\n",
      "        [-6.6154e-01, -1.0910e-01, -5.9056e-01, -6.1150e-01,  1.0865e+00,\n",
      "          9.4433e-01,  4.3388e-01,  8.9749e-02,  1.8553e+00,  2.1171e+00,\n",
      "          2.6789e-01, -3.3474e-01,  2.8402e-01,  8.2477e-03, -4.8323e-01,\n",
      "          4.8874e-01,  3.2616e-01, -2.3865e-01,  2.9448e-01,  7.0861e-01,\n",
      "          1.1112e-01,  4.3502e-01,  3.6427e-01,  1.2020e-02,  1.3885e+00,\n",
      "          2.2125e+00,  2.1803e+00,  6.3884e-01,  3.0174e+00,  3.2386e+00],\n",
      "        [-3.6136e-01, -7.6962e-01, -3.5106e-01, -4.1173e-01, -6.6855e-01,\n",
      "         -1.6059e-01, -5.0337e-01, -4.6622e-01, -9.3464e-02, -4.3364e-02,\n",
      "         -6.5666e-01, -8.3368e-01, -5.6184e-01, -4.9071e-01, -5.5622e-01,\n",
      "         -5.4117e-01, -5.7165e-01, -6.9736e-01,  8.3392e-02, -7.1910e-01,\n",
      "         -3.7702e-01, -6.1324e-01, -3.0852e-01, -4.1760e-01, -2.4877e-02,\n",
      "          3.8495e-02, -3.0372e-01, -1.9808e-01,  1.0701e+00, -1.3474e-01],\n",
      "        [-1.0212e+00,  2.5205e-01, -9.1126e-01, -8.9693e-01, -3.8052e-01,\n",
      "          1.2259e+00,  1.8000e+00,  2.9127e-01,  1.4343e+00,  3.0164e+00,\n",
      "         -1.0110e+00,  5.2773e-02, -2.4263e-01, -6.8349e-01,  4.6466e-01,\n",
      "          2.8418e+00,  4.0390e+00,  2.7729e+00, -5.2488e-01,  3.1761e+00,\n",
      "         -1.1343e+00, -4.4685e-01, -9.3379e-01, -9.2967e-01, -7.5984e-01,\n",
      "          7.6002e-01,  1.7076e+00,  5.1189e-01, -4.5951e-01,  2.0841e+00],\n",
      "        [ 5.9296e-01,  3.6848e-01,  6.0364e-01,  4.2947e-01,  1.5229e+00,\n",
      "          5.5914e-01,  7.6834e-01,  9.6751e-01,  5.3999e-01,  1.4654e-02,\n",
      "          1.1276e-01,  5.4701e-02,  1.8693e-01,  7.8093e-02, -1.1475e-01,\n",
      "         -2.5184e-01,  7.3472e-03,  3.2028e-01, -6.2605e-01, -3.7841e-01,\n",
      "          6.2430e-01,  8.1106e-01,  6.7903e-01,  4.1954e-01,  1.1841e+00,\n",
      "          3.0730e-01,  4.6557e-01,  6.9683e-01,  3.5348e-01, -8.7873e-02],\n",
      "        [-2.5659e-01, -5.0826e-01, -3.1767e-01, -3.1631e-01, -8.3729e-01,\n",
      "         -1.0434e+00, -6.7574e-01, -6.3402e-01, -1.1442e+00, -8.1832e-01,\n",
      "         -3.8640e-01, -6.0330e-01, -3.9371e-01, -3.2603e-01, -3.2857e-01,\n",
      "         -7.9656e-01, -3.2213e-01, -4.6078e-01, -6.9349e-01, -4.8908e-01,\n",
      "         -2.3934e-01, -3.1706e-01, -2.5797e-01, -3.0357e-01, -1.8144e-01,\n",
      "         -7.9487e-01, -4.5891e-01, -2.6736e-01, -6.0572e-01, -4.1767e-01],\n",
      "        [-1.6597e-01, -3.1343e-01, -2.4800e-01, -2.4405e-01, -1.1988e+00,\n",
      "         -1.2276e+00, -8.7603e-01, -9.5740e-01, -8.5733e-01, -1.0310e+00,\n",
      "         -5.0602e-01, -7.2541e-02, -5.6468e-01, -3.7641e-01, -1.0652e+00,\n",
      "         -1.1174e+00, -7.1990e-01, -1.1053e+00, -8.6586e-01, -1.0065e+00,\n",
      "         -1.6424e-01,  9.8910e-02, -2.5585e-01, -2.5042e-01, -1.1643e+00,\n",
      "         -1.1646e+00, -8.2952e-01, -9.7153e-01, -8.8046e-01, -1.1950e+00],\n",
      "        [-2.8490e-01, -1.1860e-01, -2.5872e-01, -3.4924e-01,  1.4429e+00,\n",
      "          3.8708e-01,  4.4417e-01,  6.6271e-01,  1.2107e+00,  7.0534e-01,\n",
      "         -4.0570e-01, -5.9751e-01, -4.6333e-01, -3.3483e-01, -1.6780e-01,\n",
      "         -1.1107e-01, -1.0692e-01,  3.5998e-02, -3.6750e-01, -5.5857e-02,\n",
      "         -1.2878e-01,  4.0673e-01, -1.3812e-01, -2.1481e-01,  2.0365e+00,\n",
      "          1.1285e+00,  1.1848e+00,  1.4883e+00,  1.6340e+00,  1.9640e+00],\n",
      "        [-1.6030e-01,  1.3141e+00, -1.8535e-01, -2.4321e-01, -2.4597e-01,\n",
      "         -4.8262e-01, -4.5307e-01, -4.6701e-01, -1.5681e-01, -1.8841e-01,\n",
      "         -5.9909e-01, -3.8294e-01, -5.3201e-01, -4.2537e-01, -9.5364e-01,\n",
      "         -7.5761e-01, -4.7637e-01, -8.1043e-01, -8.9209e-01, -8.7849e-01,\n",
      "          1.2572e-01,  1.6863e+00,  1.7663e-01, -5.8151e-02,  6.6660e-01,\n",
      "          2.6486e-01,  5.6716e-01,  2.9874e-01,  9.4313e-01, -2.5934e-01],\n",
      "        [ 8.1668e-01,  4.3738e-01,  8.0563e-01,  7.2215e-01,  1.1592e+00,\n",
      "          4.4908e-02,  8.0693e-01,  1.3514e+00, -2.8350e-01, -2.6991e-01,\n",
      "          1.4179e+00,  1.7840e+00,  1.5159e+00,  9.5392e-01, -1.9256e-01,\n",
      "         -4.1097e-01,  4.2511e-01,  8.8564e-01, -2.6009e-01, -2.1863e-02,\n",
      "          9.8102e-01,  1.2720e+00,  1.0846e+00,  8.4232e-01,  5.7092e-01,\n",
      "         -2.9498e-01,  6.3046e-01,  1.0792e+00, -4.1774e-01, -4.3138e-01],\n",
      "        [ 1.1438e-01, -1.3066e+00,  8.3832e-02, -2.7087e-03,  1.7152e-01,\n",
      "         -2.7614e-01, -7.5263e-02, -1.3142e-01, -2.3878e-01, -8.6528e-01,\n",
      "          4.0372e-02, -1.1180e+00, -1.4886e-01, -7.1429e-02, -6.7551e-01,\n",
      "         -4.0262e-01, -6.3612e-02, -5.2647e-01, -6.2230e-01, -5.7029e-01,\n",
      "          9.8605e-02, -1.3753e+00,  3.4386e-02, -3.4819e-02, -4.1193e-01,\n",
      "         -3.7920e-01, -9.8510e-02, -3.4447e-01, -4.1292e-01, -7.4631e-01],\n",
      "        [ 5.5332e-01, -3.0393e-01,  6.0776e-01,  4.1134e-01,  5.8464e-01,\n",
      "          1.0284e+00,  6.0883e-01,  7.7210e-01,  7.2630e-01,  3.4342e-01,\n",
      "         -2.4403e-01, -9.9852e-01, -3.2788e-01, -1.1403e-01, -9.2245e-01,\n",
      "          1.8494e-01, -1.8721e-01, -4.5917e-01, -4.1746e-01,  9.8636e-03,\n",
      "          8.1831e-01,  2.9192e-01,  7.6680e-01,  6.6514e-01,  5.5788e-01,\n",
      "          2.2320e+00,  1.3217e+00,  1.1372e+00,  2.2285e+00,  2.2727e+00],\n",
      "        [-2.9340e-01,  3.7560e-01, -2.5872e-01, -3.4282e-01, -6.7000e-01,\n",
      "          1.0943e-01,  2.6280e-01, -3.5418e-01, -8.9832e-01, -3.4036e-01,\n",
      "         -3.0883e-01, -8.0052e-01, -2.6678e-01, -2.7031e-01,  7.7528e-02,\n",
      "          3.5799e-01,  4.6275e-01,  9.8638e-02, -5.9482e-01, -2.1185e-01,\n",
      "         -3.1027e-01, -7.5795e-03, -1.9563e-01, -3.3813e-01,  1.4473e-01,\n",
      "          7.1286e-01,  9.2858e-01,  6.6784e-02, -5.1414e-01, -1.0273e-01],\n",
      "        [-8.3844e-02, -7.1260e-01, -1.6020e-01, -1.7625e-01, -1.8694e+00,\n",
      "         -1.0753e+00, -8.6985e-01, -1.0602e+00, -7.3064e-01, -1.0946e+00,\n",
      "         -5.1946e-01, -1.1217e+00, -5.5237e-01, -3.5798e-01, -1.0694e+00,\n",
      "         -6.2352e-01, -4.1241e-01, -7.8859e-01, -4.8741e-01, -6.8775e-01,\n",
      "         -1.6216e-01, -9.2106e-01, -2.3316e-01, -2.3954e-01, -2.0410e+00,\n",
      "         -8.4741e-01, -8.1370e-01, -1.0731e+00, -5.4788e-01, -9.8923e-01],\n",
      "        [-8.5410e-01,  5.3479e-01, -8.7829e-01, -7.7974e-01,  4.2463e-01,\n",
      "         -8.5099e-01, -1.0177e+00, -1.0004e+00, -7.0083e-01, -1.6907e-01,\n",
      "         -4.0777e-01,  9.1455e-01, -4.2971e-01, -4.4257e-01, -4.6907e-02,\n",
      "         -8.8547e-01, -8.4243e-01, -9.2624e-01,  8.2031e-01, -6.5376e-01,\n",
      "         -8.1927e-01,  5.6813e-01, -8.5056e-01, -7.4355e-01, -1.5534e-01,\n",
      "         -9.3163e-01, -1.1878e+00, -1.1093e+00,  1.4943e-01, -7.0345e-01],\n",
      "        [ 1.5161e+00,  3.1626e+00,  1.4734e+00,  1.5714e+00, -8.5547e-01,\n",
      "          1.8960e-01,  3.3998e-01,  4.7606e-01, -1.3976e+00, -1.3170e+00,\n",
      "          1.1528e+00,  2.2629e-01,  8.7461e-01,  1.4195e+00, -4.8709e-01,\n",
      "          6.0308e-02, -1.8721e-01, -1.8404e-01, -8.8085e-01, -5.7973e-01,\n",
      "          2.4225e+00,  3.3119e+00,  2.2044e+00,  2.7983e+00,  3.9262e-01,\n",
      "          1.0820e+00,  6.6875e-01,  7.6265e-01, -2.7313e-01, -4.4910e-01],\n",
      "        [ 5.2500e-01, -8.6704e-01,  5.5829e-01,  3.7228e-01, -7.6499e-02,\n",
      "          6.6081e-01,  4.1587e-01,  5.8332e-01, -7.8559e-02, -4.0114e-01,\n",
      "         -2.3334e-01, -8.7918e-01, -1.1665e-01, -1.5008e-01, -3.9063e-01,\n",
      "          3.9471e-01,  1.6292e-01,  4.2790e-01, -7.1223e-01, -2.5302e-01,\n",
      "          5.1582e-01, -5.8661e-01,  5.1257e-01,  3.3007e-01,  5.1004e-01,\n",
      "          1.3387e+00,  1.1593e+00,  1.3206e+00,  2.1851e-01,  4.4025e-01],\n",
      "        [ 4.4571e-01,  2.5918e-01,  4.2638e-01,  2.8327e-01,  4.7554e-01,\n",
      "          3.3429e-01,  3.4255e-01,  4.2959e-01,  4.9155e-01,  5.0570e-02,\n",
      "         -1.9818e-01, -5.4507e-01, -2.9899e-01, -1.7220e-01, -7.3564e-01,\n",
      "         -8.9922e-02, -2.8049e-01, -5.2824e-01, -3.3128e-01, -2.4924e-01,\n",
      "          6.8271e-01,  7.9608e-01,  5.6099e-01,  3.6165e-01,  1.0189e+00,\n",
      "          1.3401e+00,  6.5905e-01,  5.3383e-01,  1.7834e+00,  1.3067e+00],\n",
      "        [ 9.1729e-02, -1.9647e+00,  8.3419e-02, -5.3209e-02,  1.0283e+00,\n",
      "          1.2898e-01,  4.4923e-03,  2.4799e-01,  1.9718e-01,  1.8733e-01,\n",
      "         -3.8571e-01, -6.6827e-01, -4.4865e-01, -3.3606e-01, -1.0405e+00,\n",
      "         -7.0086e-01, -1.1458e-01,  1.1906e-02, -1.5892e-01, -3.7124e-01,\n",
      "         -1.2252e-01, -1.5850e+00, -1.3812e-01, -2.3919e-01, -2.0528e-02,\n",
      "         -4.7351e-01, -6.3797e-02,  1.2947e-01,  9.6442e-03, -1.9876e-01],\n",
      "        [-5.2561e-01, -1.6083e+00, -5.5263e-01, -5.4593e-01,  4.9736e-01,\n",
      "         -6.5488e-01, -6.2004e-01, -3.0373e-01,  5.8098e-01, -4.3015e-01,\n",
      "         -5.8185e-01, -1.0373e+00, -5.7084e-01, -4.7452e-01,  3.1868e-01,\n",
      "         -7.5427e-01, -5.1402e-01,  7.7758e-02, -1.4143e-01, -5.8275e-01,\n",
      "         -5.8146e-01, -1.6415e+00, -6.1722e-01, -5.8373e-01,  2.9259e-01,\n",
      "         -8.2518e-01, -7.3661e-01, -3.1234e-01, -8.9971e-02, -9.0464e-01],\n",
      "        [-5.0579e-01, -3.9897e-01, -4.7885e-01, -5.4928e-01,  5.9919e-01,\n",
      "          5.1612e-01, -3.7499e-01, -5.2144e-01, -8.9737e-02,  4.4426e-01,\n",
      "         -4.9636e-01, -6.3742e-01, -3.5914e-01, -4.3827e-01, -1.0896e-01,\n",
      "          6.5066e-01,  5.1006e-01, -2.2741e-01, -2.4885e-01,  1.1683e+00,\n",
      "         -4.3961e-01, -3.9527e-01, -3.6723e-01, -4.9356e-01,  4.7525e-01,\n",
      "          7.4251e-01,  2.6598e-01, -2.4761e-01, -1.0282e-01,  1.6154e+00],\n",
      "        [-1.3341e+00,  4.3975e-01, -1.3251e+00, -1.0892e+00,  6.1374e-01,\n",
      "         -5.0002e-01, -8.5352e-01, -8.8678e-01, -3.2076e-01,  8.7387e-01,\n",
      "         -5.8496e-01,  1.5565e+00, -5.7558e-01, -5.4068e-01,  1.1145e+00,\n",
      "         -4.3434e-01, -5.0369e-01, -4.1645e-01,  3.0197e-01,  1.6850e-01,\n",
      "         -1.2261e+00,  1.0074e+00, -1.2207e+00, -9.6686e-01,  1.0015e+00,\n",
      "         -5.5705e-01, -8.9017e-01, -7.6277e-01, -8.0294e-03,  4.8998e-01],\n",
      "        [-3.8535e-02, -7.5537e-01, -1.0208e-01, -1.3552e-01, -8.2783e-01,\n",
      "         -8.6722e-01, -6.7831e-01, -5.0445e-01, -3.3194e-01, -5.0889e-01,\n",
      "         -5.3738e-02, -3.0389e-01, -1.0955e-01, -1.6094e-01,  2.9649e-01,\n",
      "         -6.9028e-01, -5.3900e-01, -4.6255e-01, -4.0260e-02, -3.6293e-01,\n",
      "         -1.3086e-01, -6.5317e-01, -1.8655e-01, -2.3130e-01, -5.3370e-01,\n",
      "         -8.3461e-01, -8.0043e-01, -6.1608e-01, -2.5385e-01, -6.4000e-01],\n",
      "        [-4.4199e-02, -8.3140e-01, -1.0991e-01, -1.4863e-01, -1.1857e+00,\n",
      "         -9.2861e-01, -8.6445e-01, -5.8198e-01, -7.9771e-01, -9.3988e-01,\n",
      "         -6.5700e-01, -1.0579e+00, -6.0115e-01, -4.3725e-01, -7.1281e-01,\n",
      "         -8.9682e-01, -7.6777e-01, -1.8725e-01, -1.0819e+00, -6.3714e-01,\n",
      "         -2.8732e-01, -1.0309e+00, -3.2788e-01, -3.3848e-01, -1.2339e+00,\n",
      "         -9.9293e-01, -1.0511e+00, -4.9649e-01, -1.2002e+00, -9.3950e-01]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create dataloader object\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Print first two batches from the training dataaset\n",
    "for idx , (batch_features, batch_labels) in enumerate(train_dataloader):\n",
    "    print(batch_features)\n",
    "    print(batch_labels)\n",
    "    print('-'*50)\n",
    "\n",
    "    if idx == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Build a Neural Network Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        out = self.network(X)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MyModel                                  --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Linear: 2-1                       93\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Linear: 2-3                       4\n",
       "│    └─Sigmoid: 2-4                      --\n",
       "=================================================================\n",
       "Total params: 97\n",
       "Trainable params: 97\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an object of the model\n",
    "model = MyModel(X_train_tensor.shape[1])\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate and number of epochs\n",
    "lr = 0.01\n",
    "epochs = 50\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.68, Val Loss: 0.67\n",
      "Epoch: 1, Loss: 0.66, Val Loss: 0.65\n",
      "Epoch: 2, Loss: 0.65, Val Loss: 0.64\n",
      "Epoch: 3, Loss: 0.64, Val Loss: 0.62\n",
      "Epoch: 4, Loss: 0.63, Val Loss: 0.62\n",
      "Epoch: 5, Loss: 0.61, Val Loss: 0.60\n",
      "Epoch: 6, Loss: 0.60, Val Loss: 0.58\n",
      "Epoch: 7, Loss: 0.59, Val Loss: 0.58\n",
      "Epoch: 8, Loss: 0.58, Val Loss: 0.56\n",
      "Epoch: 9, Loss: 0.56, Val Loss: 0.54\n",
      "Epoch: 10, Loss: 0.55, Val Loss: 0.53\n",
      "Epoch: 11, Loss: 0.54, Val Loss: 0.51\n",
      "Epoch: 12, Loss: 0.53, Val Loss: 0.50\n",
      "Epoch: 13, Loss: 0.51, Val Loss: 0.48\n",
      "Epoch: 14, Loss: 0.50, Val Loss: 0.48\n",
      "Epoch: 15, Loss: 0.49, Val Loss: 0.47\n",
      "Epoch: 16, Loss: 0.48, Val Loss: 0.46\n",
      "Epoch: 17, Loss: 0.48, Val Loss: 0.43\n",
      "Epoch: 18, Loss: 0.46, Val Loss: 0.44\n",
      "Epoch: 19, Loss: 0.45, Val Loss: 0.43\n",
      "Epoch: 20, Loss: 0.44, Val Loss: 0.42\n",
      "Epoch: 21, Loss: 0.44, Val Loss: 0.42\n",
      "Epoch: 22, Loss: 0.43, Val Loss: 0.41\n",
      "Epoch: 23, Loss: 0.42, Val Loss: 0.40\n",
      "Epoch: 24, Loss: 0.41, Val Loss: 0.39\n",
      "Epoch: 25, Loss: 0.41, Val Loss: 0.37\n",
      "Epoch: 26, Loss: 0.40, Val Loss: 0.37\n",
      "Epoch: 27, Loss: 0.40, Val Loss: 0.37\n",
      "Epoch: 28, Loss: 0.39, Val Loss: 0.37\n",
      "Epoch: 29, Loss: 0.38, Val Loss: 0.35\n",
      "Epoch: 30, Loss: 0.38, Val Loss: 0.36\n",
      "Epoch: 31, Loss: 0.38, Val Loss: 0.35\n",
      "Epoch: 32, Loss: 0.37, Val Loss: 0.33\n",
      "Epoch: 33, Loss: 0.36, Val Loss: 0.33\n",
      "Epoch: 34, Loss: 0.37, Val Loss: 0.34\n",
      "Epoch: 35, Loss: 0.36, Val Loss: 0.35\n",
      "Epoch: 36, Loss: 0.35, Val Loss: 0.32\n",
      "Epoch: 37, Loss: 0.35, Val Loss: 0.33\n",
      "Epoch: 38, Loss: 0.35, Val Loss: 0.32\n",
      "Epoch: 39, Loss: 0.34, Val Loss: 0.33\n",
      "Epoch: 40, Loss: 0.35, Val Loss: 0.30\n",
      "Epoch: 41, Loss: 0.33, Val Loss: 0.30\n",
      "Epoch: 42, Loss: 0.33, Val Loss: 0.33\n",
      "Epoch: 43, Loss: 0.32, Val Loss: 0.30\n",
      "Epoch: 44, Loss: 0.32, Val Loss: 0.30\n",
      "Epoch: 45, Loss: 0.32, Val Loss: 0.29\n",
      "Epoch: 46, Loss: 0.32, Val Loss: 0.30\n",
      "Epoch: 47, Loss: 0.31, Val Loss: 0.28\n",
      "Epoch: 48, Loss: 0.31, Val Loss: 0.29\n",
      "Epoch: 49, Loss: 0.31, Val Loss: 0.28\n"
     ]
    }
   ],
   "source": [
    "# Define a loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    avg_loss = 0\n",
    "\n",
    "    # Iterate training batches\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(batch_X)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss = loss_fn(y_pred.squeeze(), batch_y)\n",
    "        avg_loss += loss\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Parameters update\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validate on testing batches\n",
    "    avg_test_loss = 0\n",
    "\n",
    "    for batch_X, batch_y in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            test_preds = model(batch_X)\n",
    "            test_loss = loss_fn(test_preds.squeeze(), batch_y)\n",
    "            avg_test_loss += test_loss\n",
    "            \n",
    "    # Print the epoch loss\n",
    "    print(f'Epoch: {epoch}, Loss: {(avg_loss / len(train_dataloader)):.2f}, Val Loss: {(avg_test_loss / len(test_dataloader)):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation using test dataloader\n",
    "model.eval() # Set the model to evaluation mode\n",
    "accuracy_list = []\n",
    "accuracy = Accuracy(task='binary')\n",
    "\n",
    "# Make predictions on testing data\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_dataloader:\n",
    "        y_pred = model(batch_X).squeeze()\n",
    "        y_pred = (y_pred > 0.5).float()\n",
    "        batch_acc = accuracy(y_pred, batch_y)\n",
    "\n",
    "        accuracy_list.append(batch_acc)\n",
    "        \n",
    "# Calculate overall accuracy\n",
    "overall_acc = np.mean(accuracy_list)\n",
    "print(f'Accuracy: {overall_acc:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
